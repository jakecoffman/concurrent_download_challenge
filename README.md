Concurrent Download Challenge
=============================

Specification
-------------

* Download the bodies of the following webpages:
  * http://google.com
  * http://python.org
  * http://ruby-lang.org
  * http://golang.org
* For each webpage downloaded, write to stdout:
  * The url
  * The size of the body in bytes of the webpage
  * The time it took to fetch the site
* If the total time to fetch the pages exceeds 0.5 seconds, the program should stop.
* The last thing the program should do is write to stdout the amount of time elapsed since the beginning of the program.
